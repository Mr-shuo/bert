{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入Numpy\n",
    "import jieba #导入结巴分词\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10428 10677\n"
     ]
    }
   ],
   "source": [
    "neg = pd.read_excel('data/neg.xls', header=None, index=None)\n",
    "pos = pd.read_excel('data/pos.xls', header=None, index=None)\n",
    "neg['mark'] = 0\n",
    "pos['mark'] = 1\n",
    "pn = pd.concat([pos,neg],ignore_index=True)\n",
    "#合并正负例\n",
    "neglen = len(neg)\n",
    "poslen = len(pos)\n",
    "print(neglen, poslen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /home/lilin/.local/lib/python3.7/site-packages/jieba/jieba.cache\n",
      "Loading model cost 0.615 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "cw = lambda x: list(jieba.cut(x))\n",
    "pn['words'] = pn[0].apply(cw)\n",
    "#apply函数：调用分词函数\n",
    "\n",
    "comment = pd.read_excel('data/sum.xls')\n",
    "comment = comment[comment['rateContent'].notnull()]\n",
    "comment['words'] = comment['rateContent'].apply(cw)\n",
    "# rateContent不为空则分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = pd.concat([pn['words'],comment['words']],ignore_index=True)\n",
    "\n",
    "w = []\n",
    "for i in w2v_train:\n",
    "    w.extend(i)\n",
    "\n",
    "dict = pd.DataFrame(pd.Series(w).value_counts())\n",
    "# print(dict[:10])\n",
    "# 统计词频\n",
    "del w,w2v_train\n",
    "dict['id'] = list(range(1,len(dict)+1))\n",
    "\n",
    "# print(dict['id'])\n",
    "\n",
    "get_sent = lambda x: list(dict['id'][x])\n",
    "pn['sent'] = pn['words'].apply(get_sent)\n",
    "# 获取相应词id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n"
     ]
    }
   ],
   "source": [
    "maxlen = 50\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "pn['sent'] = list(sequence.pad_sequences(pn['sent'], maxlen=maxlen))\n",
    "# 构建每个句子对应的单词id\n",
    "\n",
    "x = np.array(list(pn['sent']))[::2] #训练集\n",
    "y = np.array(list(pn['mark']))[::2]\n",
    "xt = np.array(list(pn['sent']))[1::2] #测试集\n",
    "yt = np.array(list(pn['mark']))[1::2]\n",
    "xa = np.array(list(pn['sent'])) #全集\n",
    "ya = np.array(list(pn['mark']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.4242 - accuracy: 0.8119\n",
      "Epoch 2/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.1733 - accuracy: 0.9390\n",
      "Epoch 3/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0770 - accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0367 - accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0230 - accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0174 - accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0183 - accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0117 - accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "660/660 [==============================] - 122s 185ms/step - loss: 0.0092 - accuracy: 0.9971\n",
      "330/330 [==============================] - 2s 7ms/step - loss: 0.6717 - accuracy: 0.8771\n",
      "loss 0.6716986298561096\n",
      "accuary 0.8770849108695984\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dict)+1, 256))\n",
    "model.add(LSTM(128)) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y, batch_size=16, epochs=10) #训练时间为若干个小时\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(xt,yt)\n",
    "print('loss',loss)\n",
    "print('accuary',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
