{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158940, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "'''\n",
    "读取训练集并构造样本\n",
    "'''\n",
    "def split_sentence(sentence):\n",
    "    stop = '[’!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]+'\n",
    "    sentence = re.sub(stop, '', sentence)\n",
    "    return sentence.split()\n",
    "\n",
    "data = pd.read_csv('data/labeledTrainData.tsv',sep='\\t')\n",
    "# data = data[:100]\n",
    "sentences = data.review.apply(split_sentence)\n",
    "\n",
    "'''\n",
    "训练word2vec\n",
    "'''\n",
    "# 嵌入维度\n",
    "embedding_vector_size = 10\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    size=embedding_vector_size,\n",
    "    min_count=1,\n",
    "    window=3,\n",
    "    workers=4,\n",
    ")\n",
    "# 生成词典列表\n",
    "vocab_list = list(w2v_model.wv.vocab.keys())\n",
    "# 生成索引\n",
    "word_index = {word: index for index, word in enumerate(vocab_list)}\n",
    "# 序列化\n",
    "def get_index(sentence):\n",
    "    global word_index\n",
    "    sequence = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            sequence.append(word_index[word])\n",
    "            # 对于每一个单词存储index\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return sequence\n",
    "\n",
    "X_data = list(map(get_index, sentences))\n",
    "\n",
    "max_len = 150\n",
    "X_pad = pad_sequences(X_data, maxlen=max_len)\n",
    "# 获取标签\n",
    "Y = data.sentiment.values\n",
    "# 划分数据集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_pad,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)\n",
    "# random_state随机数种子\n",
    "\n",
    "embedding_matrix = w2v_model.wv.vectors\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.8038 - acc: 0.5293 - val_loss: 0.6862 - val_acc: 0.5504\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.6805 - acc: 0.5705 - val_loss: 0.6848 - val_acc: 0.5520\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.6730 - acc: 0.5846 - val_loss: 0.6921 - val_acc: 0.5556\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.6657 - acc: 0.5980 - val_loss: 0.6900 - val_acc: 0.5494\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.6625 - acc: 0.6003 - val_loss: 0.6896 - val_acc: 0.5488\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.6594 - acc: 0.6080 - val_loss: 0.6874 - val_acc: 0.5506\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.6569 - acc: 0.6111 - val_loss: 0.7040 - val_acc: 0.5476\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 0.6562 - acc: 0.6124 - val_loss: 0.6935 - val_acc: 0.5464\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.6549 - acc: 0.6145 - val_loss: 0.6942 - val_acc: 0.5524\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 16s 3ms/step - loss: 0.6535 - acc: 0.6172 - val_loss: 0.7012 - val_acc: 0.5542\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "构建分类模型\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=embedding_matrix.shape[0],\n",
    "    output_dim=embedding_matrix.shape[1],\n",
    "    input_length=max_len,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=False\n",
    "))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(x=X_train,\n",
    "                   y=Y_train,\n",
    "                   validation_data=(X_test,Y_test),\n",
    "                   batch_size=4,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
